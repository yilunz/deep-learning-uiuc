{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_resnet_cifar100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yilunz/deep-learning-uiuc/blob/master/hw4_resnet_cifar100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnN9L844h8LF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import torch.distributed as dist\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from mpi4py import MPI\n",
        "import h5py\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojDAzY5RjhqX",
        "colab_type": "code",
        "outputId": "e8b64f0d-c776-474e-99bd-f4481f5823ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size=128\n",
        "LR=0.001\n",
        "Num_Epochs=100\n",
        "num_output=100\n",
        "scheduler_step_size=20\n",
        "scheduler_gamma=0.1\n",
        "c=3\n",
        "Kernel_Size=3\n",
        "\n",
        "transform_train=transforms.Compose([transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),transforms.ToTensor()])\n",
        "transform_test=transforms.ToTensor()\n",
        "\n",
        "#Load CIFAR 100 Dataset\n",
        "trainset=torchvision.datasets.CIFAR100(root='~/scratch/',train=True, download=True,transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True,num_workers=8)\n",
        "\n",
        "testset=torchvision.datasets.CIFAR100(root='~/scratch/',train=False,download=True,transform=transform_test)\n",
        "testloader=torch.utils.data.DataLoader(testset,batch_size=batch_size,shuffle=False,num_workers=8)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6EUucxMjxB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self,inplanes,planes,stride,padding,downsample=None):\n",
        "    super(BasicBlock,self).__init__()\n",
        "    self.conv1=nn.Conv2d(inplanes,planes,kernel_size=3,stride=stride,padding=padding)\n",
        "    #self.conv1=conv3x3(inplanes,planes,stride)\n",
        "    self.bn1=nn.BatchNorm2d(planes)\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        "    self.conv2=nn.Conv2d(planes,planes,kernel_size=3,stride=1,padding=padding) #stride should be 1 for the second conv\n",
        "    #self.conv2=conv3x3(planes,planes)\n",
        "    self.bn2=nn.BatchNorm2d(planes)\n",
        "    self.downsample=downsample\n",
        "    self.stride=stride\n",
        "  def forward(self,x):\n",
        "    residual=x\n",
        "    out=self.conv1(x)\n",
        "    out=self.bn1(out)\n",
        "    out=self.relu(out)\n",
        "    out=self.conv2(out)\n",
        "    out=self.bn2(out)\n",
        "    if self.downsample is not None:\n",
        "      residual = self.downsample(x)\n",
        "    #print(residual.shape)\n",
        "    #print(out.shape)\n",
        "    out+=residual\n",
        "    out=self.relu(out)\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsQNrs-aq7dE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResNet,self).__init__()\n",
        "    self.conv3=nn.Conv2d(3,32,3,stride=1,padding=1)#32, kernel_size=3, stride=1, padding=1 [32,32,32]\n",
        "    self.bn3=nn.BatchNorm2d(32)\n",
        "    self.relu1=nn.ReLU()\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "    #self.downsample1=nn.Conv2d(3,32,kernel_size=1,stride=1)\n",
        "    self.bb1=BasicBlock(32,32,1,1,downsample=None) \n",
        "    self.bb2=BasicBlock(32,32,1,1,downsample=None)\n",
        "    \n",
        "    self.downsample1=nn.Conv2d(32,64,kernel_size=1,stride=2)\n",
        "    self.bb3=BasicBlock(32,64,2,1,downsample=self.downsample1)\n",
        "    self.bb4=BasicBlock(64,64,1,1,downsample=None)\n",
        "    self.bb5=BasicBlock(64,64,1,1,downsample=None)\n",
        "    self.bb6=BasicBlock(64,64,1,1,downsample=None)\n",
        "\n",
        "    self.downsample2=nn.Conv2d(64,128,kernel_size=1,stride=2)\n",
        "    self.bb7=BasicBlock(64,128,2,1,downsample=self.downsample2)\n",
        "    self.bb8=BasicBlock(128,128,1,1,downsample=None)\n",
        "    self.bb9=BasicBlock(128,128,1,1,downsample=None)\n",
        "    self.bb10=BasicBlock(128,128,1,1,downsample=None)\n",
        "\n",
        "    self.downsample3=nn.Conv2d(128,256,kernel_size=1,stride=2)\n",
        "    self.bb11=BasicBlock(128,256,2,1,downsample=self.downsample3)\n",
        "    self.bb12=BasicBlock(256,256,1,1,downsample=None)\n",
        "\n",
        "    self.maxpool=nn.MaxPool2d(kernel_size=3,stride=1)#2*2*256\n",
        "    self.fc1=nn.Linear(2*2*256,num_output)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    out=self.conv3(x) #output size=32,32,32\n",
        "    out=self.bn3(out)\n",
        "    out=self.relu1(out)\n",
        "    out=self.dropout(out)\n",
        "    #print(out.size)\n",
        "\n",
        "    #stack1\n",
        "    out=self.bb1(out)#(in_channels,out_channels,stride)#[32,32,1]\n",
        "    out=self.bb2(out)\n",
        "\n",
        "    #stack2\n",
        "    out=self.bb3(out)\n",
        "    out=self.bb4(out)\n",
        "    out=self.bb5(out)\n",
        "    out=self.bb6(out)\n",
        "\n",
        "    #stack3\n",
        "    out=self.bb7(out)\n",
        "    out=self.bb8(out)\n",
        "    out=self.bb9(out)\n",
        "    out=self.bb10(out)\n",
        "\n",
        "    #stack4\n",
        "    out=self.bb11(out)\n",
        "    out=self.bb12(out)\n",
        "\n",
        "    #max pool\n",
        "    out=self.maxpool(out)\n",
        "    #print(out.shape)\n",
        "\n",
        "    #fully connected\n",
        "    out = out.view(-1,2*2*256) #flatten\n",
        "    out=self.fc1(out)\n",
        "    #print(out.shape)\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chno7DgbNcQH",
        "colab_type": "code",
        "outputId": "ad41f5a2-f4c9-4f21-c74a-851f7e18f9d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#basic_block=BasicBlock().to(device)\n",
        "resnet=ResNet().to(device)\n",
        "\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.RMSprop(resnet.parameters(),lr=LR,weight_decay=0.0005)\n",
        "scheduler=torch.optim.lr_scheduler.StepLR(optimizer,step_size=scheduler_step_size,gamma=scheduler_gamma)\n",
        "\n",
        "start_time=time.time()\n",
        "\n",
        "for epoch in range(Num_Epochs):\n",
        "  scheduler.step()\n",
        "  resnet.train()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  start_time = time.time()\n",
        "  for images,labels in trainloader:\n",
        "    images=images.to(device)\n",
        "    labels=labels.to(device)\n",
        "    outputs=resnet(images)\n",
        "    #print(outputs.shape)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(outputs, labels)\n",
        "    _,predicted = torch.max(outputs,1)\n",
        "    total += labels.size(0)\n",
        "    \n",
        "    correct += (predicted == labels).sum().item()\n",
        "  \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  train_accuracy = correct/total\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    resnet.eval()\n",
        "    correct=0\n",
        "    total=0\n",
        "    for images,labels in testloader:\n",
        "      #images,labels = data\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = resnet(images)\n",
        "\n",
        "      total += labels.size(0)\n",
        "      _,predicted = torch.max(outputs,1)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "    test_accuracy = correct/total\n",
        "  \n",
        "  print(\"Epoch {0}, Time {1:.4f}, Train Acc {2:.4f}, Test Acc {3:.4f}\".format(epoch, round(time.time()-start_time,4), round(train_accuracy,4), round(test_accuracy,4)))\n",
        "  torch.save(resnet.state_dict(),'epoch-{}.ckpt'.format(epoch))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:82: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, Time 78.7817, Train Acc 0.0390, Test Acc 0.0759\n",
            "Epoch 1, Time 78.5673, Train Acc 0.1109, Test Acc 0.1129\n",
            "Epoch 2, Time 78.5048, Train Acc 0.1677, Test Acc 0.1853\n",
            "Epoch 3, Time 78.6230, Train Acc 0.2125, Test Acc 0.1935\n",
            "Epoch 4, Time 78.3645, Train Acc 0.2509, Test Acc 0.1916\n",
            "Epoch 5, Time 78.2334, Train Acc 0.2888, Test Acc 0.2025\n",
            "Epoch 6, Time 78.0875, Train Acc 0.3222, Test Acc 0.2739\n",
            "Epoch 7, Time 78.0031, Train Acc 0.3535, Test Acc 0.2999\n",
            "Epoch 8, Time 77.7759, Train Acc 0.3776, Test Acc 0.3303\n",
            "Epoch 9, Time 77.8351, Train Acc 0.4013, Test Acc 0.3427\n",
            "Epoch 10, Time 77.8939, Train Acc 0.4226, Test Acc 0.3441\n",
            "Epoch 11, Time 77.6501, Train Acc 0.4390, Test Acc 0.3478\n",
            "Epoch 12, Time 77.7096, Train Acc 0.4562, Test Acc 0.3426\n",
            "Epoch 13, Time 77.9748, Train Acc 0.4678, Test Acc 0.3329\n",
            "Epoch 14, Time 77.5437, Train Acc 0.4831, Test Acc 0.3343\n",
            "Epoch 15, Time 77.5739, Train Acc 0.4925, Test Acc 0.3901\n",
            "Epoch 16, Time 77.5559, Train Acc 0.5091, Test Acc 0.3859\n",
            "Epoch 17, Time 77.7172, Train Acc 0.5169, Test Acc 0.3795\n",
            "Epoch 18, Time 77.5870, Train Acc 0.5265, Test Acc 0.4121\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}